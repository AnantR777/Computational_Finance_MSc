{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9b2814f-ae74-4cf0-80fc-00b7f772bc8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import findspark # set up the Spark environment in Python. It helps locate the Spark installation and adds it to the system path\n",
    "findspark.init() # Initializes the Spark environment so that you can use PySpark in your Python script.\n",
    "\n",
    "from pyspark import SparkConf # This module is used to configure Spark properties\n",
    "from pyspark.sql import SparkSession, functions as F # SparkSession allows you to create df, register df as tables, execute SQL over tables, etc.\n",
    "from pyspark.sql.window import Window # Used to define window specifications for window functions\n",
    "from pyspark.sql.functions import when, lit, lag, last, col, lead, countDistinct, udf, pandas_udf, PandasUDFType, coalesce, \\\n",
    "                                month, year, concat, date_format, format_string, last_day, months_between, greatest, least, abs, \\\n",
    "                                dayofweek, isnan, count # these functions are used for different DataFrame operations\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import SparkContext\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "# # from joblibspark import register_spark\n",
    "\n",
    "sc = SparkContext.getOrCreate() # creates or retrieves an existing SparkContext instance.\n",
    "sc.addPyFile('utils.py') # ensuring that file is distributed to each worker node in the cluster\n",
    "\n",
    "# for shared metastore (shared across all users)\n",
    "#spark = SparkSession.builder.appName(\"Fundamental_features2024\").getOrCreate()\n",
    "#spark.sql(\"USE 2024_06_18\");\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from sklearn import preprocessing\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, StringIndexer\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.classification import RandomForestClassifier, GBTClassifier, OneVsRest\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3cf0142-a431-474d-ad25-448ff3dc1583",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "from pyspark.sql.functions import sum, when, lit, lag, last, col, lead, countDistinct, udf, pandas_udf, PandasUDFType, coalesce, month, year, concat, date_format, format_string, last_day, months_between, greatest, least, abs, dayofweek, isnan, count, to_date, struct\n",
    "# lit creates a column with a literal value.\n",
    "# lag/lead window functions access a value in a column from a previous or next row.\n",
    "# last and col used for selecting the last value in a window and referencing columns\n",
    "# coalesce, greatest, least, abs: Various functions for handling null values, selecting maximum/minimum values, and calculating absolute values.\n",
    "# month, year, dayofweek: Functions to extract parts of a date.\n",
    "# concat, date_format, format_string: Functions for string operations.\n",
    "# last_day, months_between: Functions for date calculations.\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window # Imports the Window class, used to define window specifications for window functions.\n",
    "from pyspark.sql import SparkSession, functions as F # Imports SparkSession (entry point for Spark SQL) and functions (shorthand alias for PySpark SQL functions).\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "\n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import csv\n",
    "from functools import reduce # Imports the reduce function, used for applying a function cumulatively to items of a sequence.\n",
    "from datetime import datetime\n",
    "import os # interacting with operating system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4ff6c1-79c3-4526-ad51-3f5abc7d85e2",
   "metadata": {},
   "source": [
    "## Use outputs from experiment 1 and 2, features from part 1 of experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35e61111-27b0-4ef0-b6e4-0ff0a8b4de60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AnomalyDetection\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Specify the path where the CSV files are stored\n",
    "input_path_adj = \"/path/to/ATPSiftingAnalyticsRepo/adj.csv\"\n",
    "input_path_rf = \"/path/to/ATPSiftingAnalyticsRepo/rf_df.csv\"\n",
    "input_path_rf_train = \"/path/to/ATPSiftingAnalyticsRepo/rf_train.csv\"\n",
    "input_path_rf_test = \"/path/to/ATPSiftingAnalyticsRepo/rf_test.csv\"\n",
    "\n",
    "# Read the CSV files into a Spark DataFrame\n",
    "adj = spark.read.csv(input_path_adj, header=True, inferSchema=True)\n",
    "rf_df = spark.read.csv(input_path_rf, header=True, inferSchema=True)\n",
    "rf_train = spark.read.csv(input_path_rf_train, header=True, inferSchema=True)\n",
    "rf_test = spark.read.csv(input_path_rf_test, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e74d8e4-77ca-4178-8cae-20fd4dc6094f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#The below uses undersampling which was later discarded, instead we will adjust class weights\n",
    "# def get_balanced_train(orig_train, show_label_count_before = True, show_label_count_after = True):\n",
    "#     # Determine the size of the minority class\n",
    "#     label_counts_before = rf_train.groupBy(\"label\").count()\n",
    "#     minority_class_count = label_counts_before.agg({\"count\": \"min\"}).collect()[0][0]\n",
    "\n",
    "#     if show_label_count_before:\n",
    "#         # Show the results\n",
    "#         label_counts_before.show()\n",
    "\n",
    "#     # Sample the majority classes\n",
    "#     balanced_dfs = []\n",
    "#     for label in ['min', 'max', 'none']:\n",
    "#         label_df = orig_train.filter(col('label') == label)\n",
    "#         if label_df.count() > minority_class_count:\n",
    "#             sampled_df = label_df.sample(withReplacement=False, fraction=minority_class_count / label_df.count())\n",
    "#         else:\n",
    "#             sampled_df = label_df\n",
    "#         balanced_dfs.append(sampled_df)\n",
    "\n",
    "#     # Combine the sampled majority classes with the minority class to create a balanced dataset\n",
    "#     balanced_train = balanced_dfs[0].union(balanced_dfs[1]).union(balanced_dfs[2])\n",
    "\n",
    "#     # Verify the new class distribution\n",
    "#     label_counts_after = balanced_train.groupBy(\"label\").count()\n",
    "#     if show_label_count_after:\n",
    "#         label_counts_after.show()\n",
    "#     return balanced_train\n",
    "# rf_balanced_train = get_balanced_train(rf_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e4f4d7-4947-49ac-a76a-6ce65d61ba53",
   "metadata": {},
   "source": [
    "#### Find appropriate class weights by adjusting manually, train validate test RF/GBM model - 9 split (10 fold) cross-validation, test on final 4 years, hyperparameter tuning using grid search. Assess individual classes and models overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41b46e83-5860-4589-9234-cc230a408156",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to add class weights to the training data\n",
    "def add_class_weights(df):\n",
    "    class_weights = {\n",
    "        'max': 0.88,\n",
    "        'min': 0.88,\n",
    "        'both': 1.80,\n",
    "        'none': 0.85\n",
    "    }\n",
    "\n",
    "    # Add a weight column based on the label\n",
    "    df_with_weights = df.withColumn(\n",
    "        \"class_weights\",\n",
    "        F.when(F.col(\"label\") == 'max', class_weights['max'])\n",
    "         .when(F.col(\"label\") == 'min', class_weights['min'])\n",
    "         .when(F.col(\"label\") == 'both', class_weights['both'])\n",
    "         .when(F.col(\"label\") == 'none', class_weights['none'])\n",
    "    )\n",
    "    return df_with_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01aaa9c5-2c25-4ef6-ade7-a6a8611f979e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#handle random forest and gbm with manual class weights, hyperparam tuned, cross validated, \n",
    "def train_test_model_with_grid_search(train_df, test_df, model_type='random_forest', model_save_path=None):\n",
    "    # Add class weights to the training data\n",
    "    train_df = add_class_weights(train_df)\n",
    "\n",
    "    # Making sure no columns have nulls, if they do then fill with 0\n",
    "    double_columns = [column for column, dtype in train_df.dtypes if dtype == 'double']\n",
    "    train_df = train_df.na.fill(0, subset=double_columns)\n",
    "    test_df = test_df.na.fill(0, subset=double_columns)\n",
    "    feature_cols = [col for col in train_df.columns if col not in ['fsym', 'date', 'label', 'returns']]\n",
    "\n",
    "    # Assemble features into a vector column\n",
    "    assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "    \n",
    "    # Indexing the label column\n",
    "    label_indexer = StringIndexer(inputCol=\"label\", outputCol=\"labelindex\")\n",
    "\n",
    "    # Define model based on input (random_forest or gbm)\n",
    "    if model_type == 'random_forest':\n",
    "        # Define the Random Forest Classifier with class weights\n",
    "        model = RandomForestClassifier(labelCol=\"labelindex\", featuresCol=\"features\", weightCol=\"class_weights\")\n",
    "        \n",
    "        # Create the parameter grid for tuning Random Forest as per the new grid\n",
    "        paramGrid = ParamGridBuilder() \\\n",
    "            .addGrid(model.maxFeatures, ['auto', 'sqrt']) \\\n",
    "            .addGrid(model.maxDepth, [3, 5, 7, 10]) \\\n",
    "            .addGrid(model.minInstancesPerNode, [1, 2, 4, 8, 16]) \\\n",
    "            .build()\n",
    "\n",
    "    elif model_type == 'gbm':\n",
    "        # Define the Gradient Boosting Classifier (OneVsRest) with class weights\n",
    "        gbm = GBTClassifier(labelCol=\"labelindex\", featuresCol=\"features\", weightCol=\"class_weights\")\n",
    "        model = OneVsRest(classifier=gbm, labelCol=\"labelindex\", featuresCol=\"features\")\n",
    "        \n",
    "        # Create the parameter grid for tuning GBM as per the new grid\n",
    "        paramGrid = ParamGridBuilder() \\\n",
    "            .addGrid(gbm.maxFeatures, ['auto', 'sqrt']) \\\n",
    "            .addGrid(gbm.maxDepth, [3, 5, 7, 10]) \\\n",
    "            .addGrid(gbm.minInstancesPerNode, [1, 2, 4, 8, 16]) \\\n",
    "            .addGrid(gbm.stepSize, [0.05, 0.1, 0.2]) \\\n",
    "            .build()\n",
    "\n",
    "    # Define an evaluator with weighted F1 score for cross-validation\n",
    "    evaluator_f1_cv = MulticlassClassificationEvaluator(labelCol=\"labelindex\", predictionCol=\"prediction\", metricName=\"weightedF1\")\n",
    "\n",
    "    # CrossValidator using time series split\n",
    "    tscv = TimeSeriesSplit(n_splits=9)\n",
    "\n",
    "    pipeline = Pipeline(stages=[assembler, label_indexer, model])\n",
    "    \n",
    "    crossval = CrossValidator(estimator=pipeline,\n",
    "                              estimatorParamMaps=paramGrid,\n",
    "                              evaluator=evaluator_f1_cv,\n",
    "                              numFolds=tscv.get_n_splits(),\n",
    "                              parallelism=4)  # Adjust parallelism based on available resources\n",
    "\n",
    "    # Fit the model with cross-validation\n",
    "    cvModel = crossval.fit(train_df)\n",
    "    \n",
    "    # Save the model if save path is provided\n",
    "    if model_save_path:\n",
    "        cvModel.write().overwrite().save(model_save_path)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    predictions = cvModel.transform(test_df)\n",
    "\n",
    "    # Calculate additional metrics\n",
    "    evaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"labelindex\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"labelindex\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "    evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"labelindex\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "    evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"labelindex\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "    # Calculate and print the metrics\n",
    "    accuracy = evaluator_accuracy.evaluate(predictions)\n",
    "    precision = evaluator_precision.evaluate(predictions)\n",
    "    recall = evaluator_recall.evaluate(predictions)\n",
    "    f1 = evaluator_f1.evaluate(predictions)\n",
    "\n",
    "    print(f\"Model: {model_type}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Weighted Precision: {precision}\")\n",
    "    print(f\"Weighted Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "\n",
    "    # Calculate the confusion matrix using original categorical labels\n",
    "    label_mapping = predictions.select(\"label\", \"labelindex\").distinct()\n",
    "    label_mapping.show()\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    confusion_matrix = predictions.groupBy(\"labelindex\", \"prediction\").count()\n",
    "\n",
    "    # Display confusion matrix\n",
    "    confusion_matrix.show()\n",
    "\n",
    "    # Calculate total actual positives for each class\n",
    "    actual_positives = confusion_matrix.groupBy(\"labelindex\").agg(F.sum(\"count\").alias(\"actual_positives\"))\n",
    "\n",
    "    # Calculate true positives for each class\n",
    "    true_positives = confusion_matrix.filter(F.col(\"labelindex\") == F.col(\"prediction\")) \\\n",
    "        .select(F.col(\"labelindex\").alias(\"label_class\"), F.col(\"count\").alias(\"true_positives\"))\n",
    "\n",
    "    # Join to calculate recall for each class\n",
    "    recall_df = actual_positives.join(true_positives, actual_positives.labelindex == true_positives.label_class, \"left\") \\\n",
    "        .select(\"labelindex\", \"true_positives\", \"actual_positives\") \\\n",
    "        .withColumn(\"recall\", F.col(\"true_positives\") / F.col(\"actual_positives\"))\n",
    "\n",
    "    # Show recall for each class\n",
    "    recall_df.show()\n",
    "\n",
    "    # Return predictions to use them later if needed\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c101765-937c-400e-8626-f8349d4b6809",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.38899200456881783\n",
      "Precision: 0.4165085701979212\n",
      "Recall: 0.3889920045688178\n",
      "F1 Score: 0.3801992419670922\n",
      "+-----+----------+\n",
      "|label|labelindex|\n",
      "+-----+----------+\n",
      "|  max|       1.0|\n",
      "|  min|       0.0|\n",
      "| none|       2.0|\n",
      "+-----+----------+\n",
      "\n",
      "+----------+----------+-----+\n",
      "|labelindex|prediction|count|\n",
      "+----------+----------+-----+\n",
      "|       2.0|       0.0| 1185|\n",
      "|       1.0|       1.0| 1343|\n",
      "|       0.0|       1.0|  863|\n",
      "|       2.0|       2.0| 1299|\n",
      "|       1.0|       0.0| 2508|\n",
      "|       2.0|       1.0|  603|\n",
      "|       1.0|       2.0| 1875|\n",
      "|       0.0|       0.0| 2807|\n",
      "|       0.0|       2.0| 1525|\n",
      "+----------+----------+-----+\n",
      "\n",
      "+----------+--------------+----------------+-------------------+\n",
      "|labelindex|true_positives|actual_positives|             recall|\n",
      "+----------+--------------+----------------+-------------------+\n",
      "|       0.0|          2807|            5195| 0.5403272377285852|\n",
      "|       1.0|          1343|            5726|0.23454418442193503|\n",
      "|       2.0|          1299|            3087| 0.4207968901846453|\n",
      "+----------+--------------+----------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_test_model_with_grid_search(rf_train, rf_test, model_type='random_forest', model_save_path=\"/path/to/ATPSiftingAnalyticsRepo/RF_TP_classif\")\n",
    "# below results are displayed for 3 classes but can run to display for all 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "badc147c-3d00-41ca-b4c8-9856d30c70b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.38092518560822386\n",
      "Precision: 0.4022777710096367\n",
      "Recall: 0.38092518560822386\n",
      "F1 Score: 0.3843515446855992\n",
      "+-----+----------+\n",
      "|label|labelindex|\n",
      "+-----+----------+\n",
      "|  max|       1.0|\n",
      "|  min|       0.0|\n",
      "| none|       2.0|\n",
      "+-----+----------+\n",
      "\n",
      "+----------+----------+-----+\n",
      "|labelindex|prediction|count|\n",
      "+----------+----------+-----+\n",
      "|       2.0|       0.0|  931|\n",
      "|       1.0|       1.0| 1851|\n",
      "|       0.0|       1.0| 1287|\n",
      "|       1.0|       0.0| 2071|\n",
      "|       2.0|       2.0| 1201|\n",
      "|       2.0|       1.0|  955|\n",
      "|       1.0|       2.0| 1804|\n",
      "|       0.0|       0.0| 2284|\n",
      "|       0.0|       2.0| 1624|\n",
      "+----------+----------+-----+\n",
      "\n",
      "+----------+--------------+----------------+-------------------+\n",
      "|labelindex|true_positives|actual_positives|             recall|\n",
      "+----------+--------------+----------------+-------------------+\n",
      "|       0.0|          2284|            5195| 0.4396535129932628|\n",
      "|       1.0|          1851|            5726| 0.3232623122598673|\n",
      "|       2.0|          1201|            3087|0.38905085843861353|\n",
      "+----------+--------------+----------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_test_model_with_grid_search(rf_train, rf_test, model_type='gbm', model_save_path=\"/path/to/ATPSiftingAnalyticsRepo/GBM_TP_classif\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
